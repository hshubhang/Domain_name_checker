{
  "model_name": "model_v2",
  "version": "1.0",
  "created_at": "2025-07-07",
  "description": "LoRA fine-tuned domain generation model - v2",
  "model_config": {
    "provider": "local_lora",
    "base_model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "quantization": "8-bit",
    "lora_adapters_path": "../lora_adapters/v2/"
  },
  "lora_config": {
    "r": 32,
    "lora_alpha": 64,
    "lora_dropout": 0.05,
    "target_modules": [
      "q_proj",
      "k_proj",
      "v_proj",
      "o_proj"
    ],
    "bias": "none",
    "task_type": "CAUSAL_LM"
  },
  "training_config": {
    "num_epochs": 3,
    "learning_rate": 0.0001,
    "batch_size": 1,
    "gradient_accumulation_steps": 16,
    "warmup_steps": 100,
    "use_fp16": true,
    "use_gradient_checkpointing": true
  },
  "model_stats": {
    "trainable_params": 27262976,
    "total_params": 8057524224,
    "trainable_percentage": 0.338,
    "dataset_size": 760
  },
  "generation_config": {
    "domains_per_business": 3,
    "prompt_template": "instruction_following",
    "max_tokens": 256,
    "temperature": 0.7
  },
  "input_data": {
    "source_file": "data/augmented_dataset_v2.jsonl",
    "total_businesses": 760,
    "description": "Pre-tokenized business descriptions for LoRA fine-tuning"
  },
  "output_config": {
    "output_file": "Model Outputs/model_v2_output.jsonl",
    "format": "jsonl",
    "fields": [
      "business_description",
      "target_domains"
    ]
  },
  "evaluation_config": {
    "evaluator_model": "gpt-4",
    "metrics": [
      "relevance",
      "clarity",
      "professionalism",
      "memorability",
      "tld_suitability"
    ],
    "eval_output": "evaluator outputs/evaluated_model_v2_output.jsonl"
  },
  "system_info": {
    "platform": "Linux-6.1.0-37-cloud-amd64-x86_64-with-glibc2.36",
    "pytorch_version": "2.7.1+cu126",
    "transformers_version": "4.53.1",
    "peft_version": "0.16.0",
    "cuda_available": true,
    "training_date": "2025-07-07T04:20:17.691419",
    "gpu_name": "NVIDIA L4",
    "gpu_memory": "22.0GB"
  },
  "jupyter_utils": {
    "load_command": "load_model_version('v2')",
    "compare_with": [
      "v0"
    ],
    "experiment_ready": true
  }
}